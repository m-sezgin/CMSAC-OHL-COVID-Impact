---
title: "Does Not Playing Hockey Make You Worse At Hockey?"
subtitle: "Estimating the Impact of COVID Shutdowns on Hockey Player Development in the OHL"
author: "Jackie Jovanovic & Michele Sezgin, advised by Dr. Sam Ventura and Dr. Ron Yurko"
output: 
  html_document:
    code_folding: hide
    toc_float: true
date: 'July 29th, 2022'
---

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300&family=Source+Sans+Pro&display=swap" rel="stylesheet">
<style>

body{
font-family: 'Source Sans Pro', sans-serif;
}

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

## Introduction 

**Project Motivation**: Investigate the impact of pandemic restrictions on hockey player development.

During 2020-2021, many hockey leagues (including NHL feeder leagues) had shortened seasons or no season due to the restrictions on play caused by the COVID-19 pandemic. Some players experiencing restrictions played in other leagues or tournaments during the 2020-21 season. Others did not play any league/tournament games during the 2020-21 season. This poses the question of whether not playing games during the 2020-2021 COVID season negatively impacted player development (or caused players to get worse). 

To answer this question, we will examine data from the Ontario Hockey League, which did not play any games during the 2020-21 season. Some players from this league played in other leagues or tournaments while others did not.

```{r load-packages, include = FALSE}
# load the packages
library(tidyverse)
library(patchwork)
library(lubridate)
library(ggridges)
library(RColorBrewer)
library(kableExtra)
library(DHARMa)
library(merTools)
library(BART)
library(tidytreatment)
library(tidybayes)
library(MatchIt)
library(mgcv)
library(cobalt)
library(optmatch)
library(lme4)
```

## Data

```{r, include = FALSE}
# data wrangling

ohl <- read_csv("sams_ohl_data_request.csv")

ohl_19_20 <- ohl %>% 
  filter(season == "2019-2020", league == "OHL") %>%
  group_by(player_id, season) %>%
  summarize(pts_19 = sum(pts), gp_19 = sum(gp), teams = n()) %>%
  ungroup()
  
ohl_21_22 <- ohl %>% 
  filter(season == "2021-2022", league == "OHL") %>%
  group_by(player_id, season) %>%
  summarize(pts_21 = sum(pts), gp_21 = sum(gp), teams = n(),) %>%
  ungroup()

ohl_filtered <- inner_join(ohl_19_20, ohl_21_22, by = "player_id")

ohl_filtered <- ohl_filtered %>%
  mutate(ppg_19 = pts_19/gp_19,
         ppg_21 = pts_21/gp_21)

ohl_age_pos <- ohl %>%
  filter(league == "OHL", season %in% c("2019-2020", "2021-2022")) %>%
  group_by(player_id) %>%
  mutate(age = trunc((dob %--% as.Date("2020-01-01")) / years(1)),
         age_continuous = (dob %--% as.Date("2020-01-01")) / years(1),
         drafted = ifelse(is.na(draft_year), "No", "Yes"),
         drafted_19 = ifelse(!is.na(draft_year) & draft_year < 2020, "Yes", "No")
  ) %>%
  ungroup() %>%
  dplyr::select(player_id, age_continuous, position, drafted, drafted_19) %>%
  filter(duplicated(player_id) == FALSE)

ohl_filtered <- left_join(ohl_filtered, ohl_age_pos, by = c("player_id"))

ohl_pm <- ohl %>%
  filter(season == "2019-2020", league == "OHL") %>%
  group_by(team_name) %>%
  arrange(team_name, desc(pm)) %>%
  mutate(pm_rank_19 = 1:n(),
         pm_relative_19 = pm - mean(pm),
         pm_19 = pm
  ) %>%
  ungroup() %>%
  group_by(player_id) %>%
  mutate(pm_rank_19 = mean(pm_rank_19),
         pm_relative_19 = mean(pm_relative_19),
         pm_19 = mean(pm_19)) %>%
  filter(duplicated(player_id) == FALSE) %>%
  ungroup() %>%
  dplyr::select(player_id, pm_rank_19, pm_relative_19, pm_19)

ohl_filtered <- left_join(ohl_filtered, ohl_pm, by = c("player_id"))

ohl_treatment_prep <- ohl %>%
  filter(season == "2020-2021") %>%
  group_by(player_id) %>%
  arrange(desc(gp)) %>%
  mutate(gp_covid = sum(gp),
         championship = ifelse(league %in% c("WC","WJC-18", "WJC-20"), TRUE, FALSE),
         covid_league = league[1]) %>%
  ungroup() %>%
  dplyr::select(player_id, gp_covid, championship, covid_league) %>%
  filter(duplicated(player_id) == FALSE)

ohl_filtered <- left_join(ohl_filtered, ohl_treatment_prep)

ohl_filtered <- ohl_filtered %>%
  mutate(covid_league = replace(covid_league, is.na(covid_league), "NONE"),
         gp_covid = replace(gp_covid, is.na(gp_covid), 0),
         treatment = ifelse(gp_covid == 0, "Didn't Play", "Played"))

ohl_names <- ohl %>%
  dplyr::select(last_name, first_name, player_id) %>%
  filter(duplicated(player_id) == FALSE)

ohl_filtered <- left_join(ohl_filtered, ohl_names, by = "player_id")

write.csv(ohl_filtered, file = "~/Desktop/ohl_filtered.csv")
```

Our dataset is comprised of players who played in the Ontario Hockey League (OHL) during both the pre-COVID (2019-2020) and post-COVID (2021-2022) seasons. The dataset also includes information regarding other leagues they have played in during their career. There is information regarding season, team, league, points, games played, position, and drafted status. Each row is a player on a certain team in a specific season.

The data was was sourced from Elite Prospects and was supplied by our external advisor, Dr. Sam Ventura.

<span style="color: darkblue;">
**Snippet of Raw Data, Player Example:**
</span>

```{r, message = FALSE, warning = FALSE}
ohl %>% 
  dplyr::select(name, team_name, season, league, position, 
                gp, g, a, pts, pm) %>%
  filter(name == "Shane Wright") %>%
  arrange(desc(name)) %>% 
  knitr::kable() %>% 
  kable_styling("striped")
```

### Wrangling

**Variables added** :

- **Player Performance** : Approximated by points per game (PPG) in the post-COVID (2021-2022) season 
  - If a player played for multiple teams during this season, PPG was averaged over both teams

- **GP** : Games played (GP) in both pre-COVID season (combined if a player played for multiple teams in a season)

- **Treatment** : Whether a player played at least one game during the COVID season

- **Age** : The age of the player on January 1st, 2020

- **Player Quality** : Approximated by player PPG in the pre-COVID season

- **Drafted** : Whether a player was drafted in 2020 or earlier

- **Relative PM** : Relative plus-minus (PM) is defined as a players PM relative to the average PM of their team (\(\text{Relative PM} = PM_{player} - \mu_{PM team}\))

- **Ranked PM** : How a player's PM ranks among those of their teammates

<span style="color: darkblue;">
**Snippet of Filtered Data:**
</span>

```{r}
ohl_filtered %>% 
  dplyr::select(first_name, last_name, position, drafted, ppg_19,
                gp_21, age_continuous, treatment, ppg_21) %>%
  filter(first_name %in% c("Shane","Brandt", "Logan", "Wyatt") & last_name %in% c("Wright", "Clarke", "Mailloux", "Johnston")) %>%
  arrange(desc(last_name)) %>%
  knitr::kable() %>% 
  kable_styling("striped")
```

## Exploratory Data Analysis

#### Player Performance

```{r, fig.align = 'center', fig.cap = "Distribution of player performance is right-skewed"}
# distribution of response
ggplot(ohl_filtered, aes(x = ppg_21)) +
  geom_density(color = "royalblue3") +
  labs(title = "Distribution of player performance in post-COVID season",
       x = "Player Performance (PPG Post-COVID Season)") +
  theme_bw()
```

#### Treatment vs Performance

```{r, fig.align='center', warning=FALSE, message=FALSE}
# treatment vs ppg
ggplot(ohl_filtered, aes(x = ppg_21, color = treatment)) +
  geom_density() +
  labs(title = "Players who played during COVID season generally had higher PPG in\npost-COVID season",
       x = "Player Performance (PPG Post-COVID Season)",
       color = "COVID season") +
  scale_color_manual(values = c("royalblue3", "darkgoldenrod3")) +
  theme_bw()
```

### Possible Confounding Variables for Treatment and Response {.tabset}

#### Age

```{r, fig.align = 'center'}
# age vs ppg
ggplot(ohl_filtered, aes(x = age_continuous, y = ppg_21)) +
  geom_point(alpha = .5) +
  labs(title = "Weak, slightly positive relationship between player performance and age",
       x = "Age in Pre-COVID Season",
       y = "Player Performance (PPG Post-COVID Season)") +
  theme_bw() +
  geom_smooth(method = "lm") 

# age vs treatment
ggplot(ohl_filtered, aes(x = age_continuous, color = treatment)) +
  geom_density() +
  labs(title = "More 17- and 18-year-olds played during COVID season",
       x = "Age in Pre-COVID Season",
       color = "COVID Season") +
  scale_color_manual(values = c("royalblue3", "darkgoldenrod3")) +
  theme_bw() 
```

#### GP

```{r, fig.align = 'center'}
# gp vs ppg
ggplot(ohl_filtered, aes(x = gp_21, y = ppg_21)) +
  geom_point(alpha = .5) +
  labs(title = "Positive linear relationship between player performance and GP in \npost-COVID season",
       x = "GP in Post-COVID Season", 
       y = "Player Performance (PPG Post-COVID Season)") +
  theme_bw() +
  geom_smooth(method = "lm")

ggplot(ohl_filtered, aes(x = gp_21, color = treatment)) +
  geom_density() +
  labs(title = "Skaters who played during COVID season played more games\nin post-COVID season",
       x = "GP in Post-COVID Season",
       color = "COVID Season") +
  scale_color_manual(values = c("royalblue3", "darkgoldenrod3")) +
  theme_bw() 
```

#### Drafted

```{r, fig.align = 'center'}
# drafted vs ppg
ggplot(ohl_filtered) +
  geom_density(aes(x = ppg_21, color = drafted_19)) +
  labs(title = "Post-COVID season player performance generally greater for drafted players",
       x = "Player Performance (PPG in Post-COVID Season)",
       color = "Drafted") +
  scale_color_manual(values = c("royalblue3", "darkgoldenrod3")) +
  theme_bw()

# drafted status vs treatment
mosaicplot(table("Drafted" = ohl_filtered$drafted_19,
                 "COVID Season" = ohl_filtered$treatment),
           main = "Drafted players more likely to have played during COVID season",
           shade = TRUE)
```

#### Player Quality

```{r, fig.align = 'center'}
# ppg 2019-20 vs ppg 21-22
ggplot(ohl_filtered, aes(x = ppg_19, y = ppg_21)) +
  geom_point(alpha = .5) +
  labs(title = "Positive linear relationship between post-COVID season player performance \nand player quality",
       x = "Player Quality (PPG in pre-COVID Season)",
       y = "Player Performance (PPG Post-COVID Season)") +
  geom_smooth(method = "lm") +
  theme_bw()

ggplot(ohl_filtered, aes(x = ppg_19, color = treatment)) +
  geom_density() +
  labs(title = "Skaters who played during COVID season were higher quality players",
       x = "Player Quality (PPG in Pre-COVID Season)",
       color = "COVID Season") +
  scale_color_manual(values = c("royalblue3", "darkgoldenrod3")) +
  theme_bw()
```

#### Position

```{r, fig.align = 'center'}
# position vs ppg
ggplot(ohl_filtered) +
  geom_density(aes(x = ppg_21, color = position)) +
  labs(title = "Post-COVID season player performance generally greater for forwards",
       x = "Player Performance (PPG in Post-COVID Season)",
       color = "Position") +
  scale_color_manual(values = c("royalblue3", "darkgoldenrod3")) +
  theme_bw()

# position vs treatment
mosaicplot(table("Position" = ohl_filtered$position,
                 "COVID Season" = ohl_filtered$treatment),
           main = "Player position does not significantly influence probability\nof playing during COVID Season",
           shade = TRUE)
```

### {-}

## Methods

### Regression

Before performing causal analysis, we wanted to determine whether playing during the COVID season had a significant effect on PPG when controlling for variables (and interactions between variables) suspected to be associated with the response through EDA. When possible, we attempted a few different measures of player quality/player performance, including PPG z-scores (to control for differences in overall scoring across seasons) and relative plus-minus (PM) scores (computes player's PM relative to their team).

__Ordinary Least Squares (OLS)__ : We fit OLS without interaction, because this model is the simplest and most interpretable model to assess the significance of playing during COVID while still controlling for variables that could be confounding our analysis.

**Interaction OLS** : We then fit OLS with interaction to control for the relationships we observed between explanatory variables in our EDA process. We also tested whether the additional complexity of this full model significantly increased our predictive power over the nested model.

**Gamma** : PPG is right skewed and bounded between 0 and some positive number, so we believed PPG may be Gamma-distributed. We performed Gamma regression with the log link function to see if this would more accurately model the relationship between our response and explanatory variables.

**Mixed-effects Model** : Lastly, we fit a mixed-effects model to determine if the effect of playing during the COVID season was significantly different across leagues. We let the slope and intercept of the regression line vary according to the league, with players who didn't play during the COVID season all grouped into a league called "NONE".

```{r, include = FALSE}
# Basic OLS Regression
ohl_mlr <- lm(ppg_21 ~ position + ppg_19 + treatment + drafted_19 + gp_21 + age_continuous, data = ohl_filtered)
summary(ohl_mlr)
```

```{r, include = FALSE}
# Interaction OLS Regression
ohl_mlr_interaction <- lm(ppg_21 ~ position*ppg_19 + + age_continuous*ppg_19 + ppg_19*treatment + ppg_19*drafted_19 + drafted_19*age_continuous + gp_21, data = ohl_filtered)
plot(ohl_mlr_interaction, which = c(1, 2))
summary(ohl_mlr_interaction)
```

```{r, include = FALSE}
# is the full model significantly different from the nested?
anova(ohl_mlr, ohl_mlr_interaction)
# no.
```

```{r, include = FALSE}
# shift ppg by .001 for gamma regression
ohl_filtered <- ohl_filtered %>%
  mutate(ppg_alt = ppg_21 + .001)

ohl_glm_simple <- glm(ppg_alt ~ position + ppg_19 + treatment + drafted_19 + gp_21 + age_continuous, data = ohl_filtered, family = Gamma)

# fit gamma regression model
ohl_glm_interaction <- glm(ppg_alt ~  position*ppg_19 + age_continuous*ppg_19 + ppg_19*treatment + ppg_19*drafted_19 + drafted_19*age_continuous + gp_21,
                          data = ohl_filtered,
                          family = Gamma)

plot(ohl_glm_simple, which = 1)
plot(ohl_glm_interaction, which = 1)

summary(ohl_glm_simple)
summary(ohl_glm_interaction)

simout_simple <- simulateResiduals(ohl_glm_simple)
plotSimulatedResiduals(simout_simple)
simout_interaction <- simulateResiduals(ohl_glm_interaction)
plotSimulatedResiduals(simout_interaction)
```

```{r, include = FALSE}
ohl_filtered <- ohl_filtered %>%
  mutate(treatment_numeric = ifelse(treatment == "Played", 1, 0))

ohl_lmer <- lmer(ppg_21 ~ position + ppg_19 + gp_19 + age_continuous + drafted_19 + treatment_numeric + (treatment_numeric|covid_league),
                     data = ohl_filtered)
summary(ohl_lmer)
```

```{r, include = TRUE}
league_effects <- REsim(ohl_lmer)

league_effects %>%
  as_tibble() %>%
  group_by(groupFctr) %>%
  arrange(desc(mean)) %>%
  slice(1:5, (n() - 4):n()) %>%
  ggplot(aes(x = reorder(groupID, mean))) +
  geom_point(aes(y = mean)) +
  geom_errorbar(aes(ymin = mean - 2 * sd,
                    ymax = mean + 2 * sd)) +
  facet_wrap(~groupFctr, ncol = 1, scales = "free_y") +
  geom_vline(xintercept = 0, linetype = "dashed",
             color = "red") +
  coord_flip() +
  theme_bw() +
  labs(title = "League effect sizes")
plotREsim(league_effects, labs = TRUE)
```

```{r}
ohl_filtered %>%
 group_by(covid_league) %>%
 summarize(n())
```


```{r}
ohl_filtered %>%
  filter(covid_league %in% c("HockeyEttan", "SL", "WJC-18")) %>%
  group_by(covid_league) %>%
  summarize(n())
```


```{r, include = FALSE}
# final model choice based on significant terms in non-interaction OLS and interaction OLS
# did not include points in 19-20 because points are very correlated with ppg
ohl_mlr_final <- lm(ppg_21 ~ position + ppg_19 + treatment + gp_21 + age_continuous, data = ohl_filtered)
summary(ohl_mlr_final)
```

```{r}
rmse_baseline <- sqrt(mean)
rmse_ols <- sqrt(mean(ohl_mlr$residuals^2))
rmse_ols_int <- sqrt(mean(ohl_mlr_interaction$residuals^2))
rmse_gamma_sim <-sqrt(mean(ohl_glm_simple$residuals^2))
rmse_gamma_int <- sqrt(mean(ohl_glm_interaction$residuals^2))
rmse_lmer <- sqrt(mean(residuals(ohl_lmer)^2))
tibble(model = c("ols", "ols interaction", "gamma simple", "gamma interaction", "mixed effects"),
       RMSE = c(rmse_ols, rmse_ols_int, rmse_gamma_sim, rmse_gamma_int, rmse_lmer))
```


### Causal Analysis

## Results

The most appropriate regression model fit was OLS regression. The model explained approximately 59% of the variance in the data without sacrificing interpretability. Interaction OLS regression only marginally increased the variance explained and was not significantly different from OLS regression. Conditions for inference for both of these models were mostly met. Though Gamma regression fit the data well, the model conditions for inference were not met (the residuals were not gamma-distributed). Lastly, it was found that the effect of playing during COVID did not significantly differ across leagues in our mixed-effects model, so the extra complexity of the model was deemed unnecessary.

#### The results of the OLS regression model are as follows:

\(\widehat{\text{Player Performance}} = 1.14 + 0.053*\text{Treatment} + 0.18*\text{Forward} +  0.89*\text{Player Quality} +  0.006*\text{Games Played Post-COVID}\\- 0.07*\text{Age} \)

```{r, fig.align='center'}
ohl_filtered %>%
  mutate(pred_vals = predict(ohl_mlr_final)) %>%
  ggplot(aes(x = pred_vals,
             y = ppg_21)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0,
              linetype = "dashed",
              color = "red",
              size = 2) +
  theme_bw() +
  labs(title = "Model fit: Actual PPG in post-COVID season vs predicted PPG in\npost-COVID season",
       x = "Predicted PPG in post-COVID season",
       y = "Actual PPG in Post-COVID Season")
```

* Coefficients for position, games played in post-COVID season, age, and previous player quality were all found to be statistically significant from 0 at the \(\alpha = 0.01\) level.

* The model explains approximately 59% of the variation in player performance in the post-COVID season, which is a statistically significant amount at the \(\alpha = .001\) level \(F(5, 213) = 62.88, p<.001\).

```{r, include = FALSE}
confint(ohl_mlr_final)
```

#### Propensity Score Matching

The first match we tried was using the nearest neighbor method. This approach does not optimize criterion, so we switched to optimal pair matching. The absolute within-pair difference of each covariate was smaller in the optimal match, hence better balanced. 

```{r opt_propensity, fig.align='center'}
opt_propensity_match <- 
  matchit(treatment_numeric ~ gp_19 + position + pts_19 + ppg_19 + 
            age_continuous + pm_rank_19, 
          data = ohl_filtered, method = "optimal",
          distance = "gam",
          replace = FALSE, # do not reuse controls
          ratio = 1)
plot(opt_propensity_match, type = "jitter", interactive = FALSE)
```

The dots are aligned fairly well on this plot. They are similar in range and have minimal gaping. 

```{r love-plot, fig.align='center'}
plot(summary(opt_propensity_match))
```

The Love plot indicates that position, age, and plus-minus are well-balanced. Ideally, the all of the dots would be around the two lines. The points for distance, games played, points, and points per game are further left for the matched data than all of the data. The new model of matched data allows us to make more accurate inferences.  

<span style="color: darkblue;">
**The following model was fit using only the matched data:**
</span>

<span style="color: darkblue;">
ppg_21_22 ~ position + ppg_19_20 + treatment + gp_21_22 + age_continuous + pts_19_20
</span>

```{r lm_opt_prop, fig.align='center'}
opt_matched <- match.data(opt_propensity_match)

opt_match_lm <- lm(ppg_21 ~ position + ppg_19 + treatment + gp_21 + age_continuous,
                    data = opt_matched)

plot(opt_match_lm, which = 1)
summary(opt_match_lm)
```

\(\widehat{\text{Player Performance}} = 1.145 + 0.054*\text{Treatment} + 0.212*\text{Forward} +  0.852*\text{Player Quality} +  0.0037*\text{Games Played Post-COVID}\\- 0.0644*\text{Age} \)

```{r, include = FALSE}
confint(opt_match_lm)
```


* Coefficients for position, games played in post-COVID season, and player quality were all found to be statistically significant from 0 at the \(\alpha = 0.05\) level.

* The model explains approximately 58% of the variation in player performance in the post-COVID season, which is a statistically significant amount at the \(\alpha = .001\) level \(F(5, 128) = 37.53, p<.001\).

The linear model appears like a good fit for this data. It meets the majority of requirements for linearity. There are no large curves and the errors are evenly spread.

#### Distribution Plots of Individual Variables {.tabset}

##### Distance

```{r opt_distance, fig.align='center'}
bal.plot(opt_propensity_match, var.name = "distance",
         colors = c("goldenrod1", "dodgerblue"))
```

##### Games Played

```{r opt_gamesplayed, fig.align='center'}
bal.plot(opt_propensity_match, var.name = "gp_19",
         colors = c("goldenrod1", "dodgerblue"))
```

##### Position

```{r opt_position, fig.align='center'}
bal.plot(opt_propensity_match, var.name = "position",
         colors = c("goldenrod1", "dodgerblue"))
```

##### Points

```{r opt_points, fig.align='center'}
bal.plot(opt_propensity_match, var.name = "pts_19",
         colors = c("goldenrod1", "dodgerblue"))
```

##### Points Per Game

```{r opt_ppg, fig.align='center'}
bal.plot(opt_propensity_match, var.name = "ppg_19",
         colors = c("goldenrod1", "dodgerblue"))
```

##### Age

```{r opt_age, fig.align='center'}
bal.plot(opt_propensity_match, var.name = "age_continuous",
         colors = c("goldenrod1", "dodgerblue"))
```

##### Plus-Minus

```{r opt_plusminus, fig.align='center'}
bal.plot(opt_propensity_match, var.name = "pm_rank_19",
         colors = c("goldenrod1", "dodgerblue"))
```

#### {-}

#### Fitting Bayesian Additive Regression Trees to Observe Treatment Effects

An appeal of BART is that it controls overfitting, which is one issue with normal additive regression trees. Each tree tries to account for something new in the model. Once all added, accurate estimates are produced. This allows for causal inferences to be drawn.

```{r bart-data, include = FALSE}
# ohl_update <- ohl_filtered
# 
# # ohl_filtered_b <- ohl_filtered_b %>%
# #   mutate(got_drafted = case_when(!is.na(draft_year) & draft_year < 2020
# #                                  ~ 'Yes',
# #                                  TRUE ~ 'No'))
# 
# # convert treatment to binary indicator:
# # ohl_update <- ohl_filtered_b %>%
# #   mutate(treatment = ifelse(treatment == "Played", 1, 0),
# #          treatment = as.integer((treatment)))
# 
# # convert categorical variables to binary
# ohl_update <- ohl_update %>%
#   mutate(is_forward = case_when(position == "F" ~ 1,
#                                 position == "D" ~ 0)) %>%
#   mutate(is_drafted = case_when(drafted_19 == "Yes" ~ 1,
#                                 drafted_19 == "No" ~ 0)) %>%
#   # mutate(s_played = case_when(season == "2021-2022" ~ 1,
#   #                             season == "2019-2020" ~ 0)) %>%
#   as.data.frame()
```

# BEGIN BART EXPERIMENTING

```{r fit-var-sel, message = FALSE, warning = FALSE, results='hide'}
# # fit variable selection model
# var_select_bart <- wbart(x.train = dplyr::select(ohl_update, gp_19,
#                                                  pts_19, age_continuous, 
#                                                  pm_relative_19, pm_19, 
#                                                  is_forward, is_drafted,
#                                                  ppg_19),
#                        y.train = pull(ohl_update, ppg_21),
#                        sparse = TRUE,
#                        ntree = 25,
#                        ndpost = 50)
# # without draft
var_select_bart_nodr <- wbart(x.train = dplyr::select(ohl_update, gp_19,
                                                 pts_19, age_continuous,
                                                 pm_relative_19, pm_19,
                                                 is_forward, ppg_19),
                       y.train = pull(ohl_update, ppg_21),
                       sparse = TRUE,
                       ntree = 25,
                       ndpost = 50)
```

```{r}
# variable selection
# covar_ranking <- covariate_importance(var_select_bart)
# var_select <- covar_ranking %>% 
#   filter(avg_inclusion >= quantile(avg_inclusion, 0.5)) %>% 
#   pull(variable)
# 
# # without draft
# covar_ranking_nodr <- covariate_importance(var_select_bart_nodr)
# var_select_nodr <- covar_ranking_nodr %>% 
#   filter(avg_inclusion >= quantile(avg_inclusion, 0.5)) %>% 
#   pull(variable)
```

```{r prop-scr-mdl, message = FALSE, warning = FALSE, results='hide'}
# fit a propensity score model
# prop_bart <- pbart(x.train = dplyr::select(ohl_update, all_of(var_select)),
#                   y.train = pull(ohl_update, treatment),
#                   nskip = 2000,
#                   ndpost = 5000)
# # store propensity score in data
# ohl_update$prop_score <- prop_bart$prob.train.mean
# # copy of ohl_update
# ohl_update2 <- ohl_update
# # without draft
# prop_bart_nodr <- pbart(x.train = dplyr::select(ohl_update2, 
#                                                 all_of(var_select_nodr)),
#                   y.train = pull(ohl_update2, treatment),
#                   nskip = 2000,
#                   ndpost = 5000)
# ohl_update2$prop_score <- prop_bart_nodr$prob.train.mean
```

```{r fit-trt-ef, message = FALSE, warning = FALSE, results='hide'}
# fit the treatment effect model
# te_model <- wbart(x.train = dplyr::select(ohl_update, gp_19_20, pts_19_20,
#                                   age_continuous, pm_relative_19_20,
#                                   pm_rank_19_20, pm_19_20, is_forward,
#                                   is_drafted, treatment, prop_score),
#                                   # need to include treatment and prop score
#                  y.train = pull(ohl_update, ppg_19_20),
#                  nskip = 10000L,
#                  ndpost = 200L,
#                  keepevery = 100L)
# te_model <- wbart(x.train = dplyr::select(ohl_update, gp_19_20, pts_19_20,
#                                   age_continuous, pm_relative_19_20,
#                                   pm_19_20, is_forward,
#                                   is_drafted, ppg_19_20, treatment, prop_score),
#                                   # need to include treatment and prop score
#                  y.train = pull(ohl_update, ppg_21_22),
#                  nskip = 10000L,
#                  ndpost = 200L,
#                  keepevery = 100L)
# # without draft
# te_model_nodr <- wbart(x.train = dplyr::select(ohl_update2, gp_19_20, pts_19_20,
#                                   age_continuous, pm_relative_19_20,
#                                   pm_19_20, is_forward,
#                                   ppg_19_20, treatment, prop_score),
#                                   # need to include treatment and prop score
#                  y.train = pull(ohl_update2, ppg_21_22),
#                  nskip = 10000L,
#                  ndpost = 200L,
#                  keepevery = 100L)
```

```{r extratct-post, message = FALSE, warning = FALSE}
# extract the posterior
# posterior_fitted <- fitted_draws(te_model, value = "fit",
#                                  include_newdata = FALSE)
# posterior_fitted
# # function to tidy predicted draws and add random normal noise by default
# posterior_pred <- predicted_draws(te_model, include_newdata = FALSE)
# # without draft
# posterior_fitted_nodr <- fitted_draws(te_model_nodr, value = "fit",
#                                  include_newdata = FALSE)
# posterior_fitted_nodr
# posterior_pred_nodr <- predicted_draws(te_model_nodr, include_newdata = FALSE)
```

```{r}
# load rds files
# var_select_bart <- readRDS("var_select_bart.rds")
# prop_bart <- readRDS("prop_bart.rds")
# te_model <- readRDS("te_model.rds")
```

```{r fit_bart_reg_model}
# fit variable selection model
# var_select_bart

# variable selection
# covar_ranking <- covariate_importance(var_select_bart)
# var_select <- covar_ranking %>% 
#   filter(avg_inclusion >= quantile(avg_inclusion, 0.5)) %>% 
#   pull(variable)
# 
# # fit a propensity score model
# # prop_bart
# 
# # store propensity score in data
# ohl_update$prop_score <- prop_bart$prob.train.mean

# fit the treatment effect model
# te_model
```

```{r extract-posterior, include=FALSE}
# extract the posterior
# posterior_fitted <- fitted_draws(te_model, value = "fit",
#                                  include_newdata = FALSE)
# posterior_fitted
# 
# # function to tidy predicted draws and add random normal noise by default
# posterior_pred <- predicted_draws(te_model, include_newdata = FALSE)
```

#### Treatment Effects {.tabset}

```{r calc-treat-ef, include = FALSE}
# sample based (using data from fit) conditional treatment effects,
# posterior draws
# posterior_treat_eff <- 
#   treatment_effects(te_model, treatment = "treatment",
#                     # the dataset here needs to match the BART data EXACTLY
#                     # which is really annoying...
#                     newdata = dplyr::select(ohl_update, gp_19_20, pts_19_20, 
#                                      age_continuous, pm_relative_19_20, 
#                                      pm_rank_19_20, is_forward, pm_19_20,
#                                      is_drafted, treatment, prop_score))
```

##### All Draws

```{r, trt_ef_all, message = FALSE, warning = FALSE, fig.align = 'center'}
# histogram of treatment effect (all draws)
# posterior_treat_eff %>% 
#   ggplot() +
#   geom_histogram(aes(x = cte), bins = 50, color = "white") +
#   geom_vline(xintercept = 0, color = "red", size = 1) +
#   theme_bw() + ggtitle("Histogram of treatment effect (all draws)")
```

##### Mean For Each Subject

```{r trt_ef_sub, message = FALSE, warning = FALSE, fig.align = 'center'}
# histogram of treatment effect (mean for each subject)
# posterior_treat_eff %>% summarise(cte_hat = mean(cte)) %>%
#   ggplot() +
#   geom_histogram(aes(x = cte_hat), bins = 60, colour = "white") + 
#   geom_vline(xintercept = 0, color = "red", size = 1) +
#   theme_bw() + 
#   ggtitle("Histogram of treatment effect (mean for each subject)")
```

##### CIs of the CATEs

```{r ci-cate, message = FALSE, warning = FALSE, fig.align = 'center'}
# posterior CIs of the CATEs
# posterior_treat_eff %>% dplyr::select(-treatment) %>% point_interval() %>%
#   arrange(cte) %>% mutate(.orow = 1:n()) %>% 
#   ggplot() + 
#   geom_interval(aes(x = .orow, y= cte, ymin = .lower, ymax = .upper)) +
#   geom_point(aes(x = .orow, y = cte), shape = "circle open", alpha = 0.5) + 
#   ylab("Median posterior CATE for each subject (95% CI)") +
#   theme_bw() + coord_flip() + scale_colour_brewer() +
#   theme(axis.title.y = element_blank(), 
#         axis.text.y = element_blank(), 
#         axis.ticks.y = element_blank(),
#         legend.position = "none")
```

#### {-}

## Results

### Linear Regression

The most appropriate regression model fit was OLS regression. The model explained approximately 59% of the variance in the data without sacrificing interpretability. Interaction OLS regression only marginally increased the variance explained and was not significantly different from OLS regression. Conditions for inference for both of these models were mostly met. Though Gamma regression fit the data well, the model conditions for inference were not met (the residuals were not gamma-distributed). Lastly, it was found that the effect of playing during COVID did not significantly differ across leagues in our mixed-effects model, so the extra complexity of the model was deemed unnecessary.

#### The results of the OLS regression model are as follows:

\(\widehat{\text{Player Performance}} = 0.901 + 0.0655*\text{Treatment} + 0.188*\text{Forward} +  0.862*\text{Player Quality} +  0.00559*\text{Games Played Post-COVID}\\- 0.0556*\text{Age} \)

```{r, fig.align='center'}
ohl_filtered %>%
  mutate(pred_vals = predict(ohl_mlr_final)) %>%
  ggplot(aes(x = pred_vals,
             y = ppg_21)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0,
              linetype = "dashed",
              color = "red",
              size = 2) +
  theme_bw() +
  labs(title = "Model fit: Actual PPG in post-COVID season vs predicted PPG in\npost-COVID season",
       x = "Predicted PPG in post-COVID season",
       y = "Actual PPG in Post-COVID Season")
```

* Coefficients for position, points in pre-COVID season, games played in post-COVID season, and age were all found to be statistically significant from 0 at the \(\alpha = 0.05\) level.

* The model explains approximately 59% of the variation in player performance in the post-COVID season, which is a statistically significant amount at the \(\alpha = .001\) level \(F(5, 213) = 62.78, p<.001\).

```{r, include = FALSE}
confint(ohl_mlr_final)
```

```{r, include = FALSE}
# It was found that the effect of playing during COVID did significantly differ across leagues in our mixed-effects model, with the treatment effect being significantly different from zero (postive treatment effect) for the U18 World Junior Championships, Swiss League, and Hockeyettan.
league_effects <- REsim(ohl_lmer)

league_effects %>%
  as_tibble() %>%
  group_by(groupFctr) %>%
  arrange(desc(mean)) %>%
  slice(1:5, (n() - 4):n()) %>%
  ggplot(aes(x = reorder(groupID, mean))) +
  geom_point(aes(y = mean)) +
  geom_errorbar(aes(ymin = mean - 2 * sd,
                    ymax = mean + 2 * sd)) +
  facet_wrap(~groupFctr, ncol = 1, scales = "free_y") +
  geom_vline(xintercept = 0, linetype = "dashed",
             color = "red") +
  coord_flip() +
  theme_bw() +
  labs(title = "League effect sizes")
plotREsim(league_effects, labs = TRUE)
```

#### Propensity Scores

After selecting the linear regression model, we matched the data and refit the model to see if this affected the treatment impact. At alpha = 0.01, the position, age, and points variables were significant. There is no evidence that treatment is significant in the matched model.

#### BART

## Discussion

#### OLS Regression Model Interpretation

Player performance in the post-COVID season is expected to increase by .0655 PPG on average for skaters who played during COVID, when holding constant position, player quality, games played in the post-COVID season, points scored in the pre-COVID season, and continuous age.

Over the course of a 68 game season in the OHL, the treatment effect would result in only approximately 4 extra points!

In this model, the coefficient for whether someone played during the COVID-season was not statistically significantly different from zero. There is no evidence that playing during the COVID season impacted player performance in the post-COVID season for players who played in both the pre- and post-COVID seasons in the OHL. 

We are 95% confident that the change in player performance in the post-COVID for players who played during the COVID season is between -0.0185 and 0.149 PPG, holding constant position, player quality, games played in the post-COVID season, points scored in the pre-COVID season, and continuous age.

This model can be used to predict player performance in the post-COVID season based on a variety of factors in the pre-, COVID, and post-COVID seasons among skaters who played in the OHL in both the pre- and post-COVID seasons.

### Limitations

#### OLS Regression Model Limitations

The model conditions for inference were not all met.

- Linearity: The relationship between our explanatory variables and post-COVID season PPG looks roughly linear. This condition is met.

- Independence: All of the skaters are playing together in the same league and influencing each other's player performance/PPG. Because we were using player level data, and not play level data, we could not attempt to account for this non-independence. Therefore this condition is not met.

- Normality of Residuals: The residuals seem roughly normally distributed in the normal QQ plot. This condition is met.

- Homogeneity of errors: There seems to be roughly constant variance in residuals across all levels of our explanatory variables. This condition is met.

```{r, fig.align='center'}
plot(ohl_mlr_final, which = c(1, 2))
```

**Matched OLS Model Interpretation**

Player performance in the post-COVID season is expected to increase by .054 PPG on average for skaters who played during COVID, when holding constant position, player quality, games played in the post-COVID season, points scored in the pre-COVID season, and continuous age.

Again, over the course of a 68 game season in the OHL, the treatment effect would result in only approximately 4 extra points!

In this model, the coefficient for whether someone played during the COVID-season was not statistically significantly different from zero. There is no evidence that playing during the COVID season impacted player performance in the post-COVID season for players who played in both the pre- and post-COVID seasons in the OHL. 

We are 95% confident that the change in player performance in the post-COVID for players who played during the COVID season is between -0.0488 and 0.157 PPG, holding constant position, player quality, games played in the post-COVID season, points scored in the pre-COVID season, and continuous age.

#### Player Performance

We defined player performance as PPG in the post-COVID season, but this may not adequately capture all aspects of a player's performance.Though we control for position in our model, PPG will generally be higher for forwards than defensemen. defensive performance is not well-approximated by PPG, and this measure would bias offensive defensemen as the best-performing defensemen, even though defensive defensemen may be performing well by blocking a lot of shots, making successful breakout plays,and creating lots of turnovers. Good defensive forwards may be undervalued using this metric as well.

#### Player quality

We used PPG in the pre-COVID season as a proxy for player quality, even though this again does not account for all of the statistics that might measure the quality of a player. This has many of the same issues as player performance above.
 
#### Treatment Variable

Our treatment variable was defined as players who participated in at least one game during the COVID season in any league or tournament. Though we attempted to control for the quality of the league in our mixed effect model, we could have tried different groupings of leagues or implemented some league quality metric that would have better controlled for its effect. Additionally, the sample size of players in some leagues was small, so we could not get very reliable estimates of the treatment effect of that league.Future analysis could provide a more distinct view of the treatment variable in which both league quality and number of games played are thoroughly controlled for.

#### Future work

- Future work could involve redefining/tweaking treatment and response variables (possibly with more detailed data) and refitting models to better estimate the effect of playing during the COVID season. A more nuanced measure that incorporates important defensive statistics like turnovers created, passes completed, shots blocked, etc. may better approximate player performance. In the future, we could study the effect of playing or not playing during the COVID season in other populations (NHL taxi squad, goalies, other minor leagues), in addition to studying the effect of taking time off due to injury/other circumstances on player performance long-term.

- Additionally, adding information about what line somebody plays on could control for confounding in our model. Likely only the best players/first-liners were able to go to play in other leagues during the COVID season. If we could control for line status affecting who could go play during COVID, we could get a more accurate estimate of the treatment effect.

- Another factor that could influence whether skaters played during the COVID season is drafted status prior to the COVID season. If a player was drafted prior to the OHL shutdown, their NHL team would have had more resources and power to convince a league to take that player on for the year. In this dataset, though we tried to control for this drafted effect, the number of players drafted was so small and the overlap between players who were drafted and players who were treated was so significant that we decided not to include draft status in our models.

- In our dataset, we only studied players who played in the OHL both before and after the COVID season, but there could be a significant number of players who played during the COVID season (considered treated) and were so good that they moved on to better leagues like the AHL/NHL post-COVID season. This could be confounding our analysis, because if this were the case, then including these players would likely result in the treatment effect being significant.

- We also did not utilize weighting in our model, which could have improved our estimate of the treatment effect. If we had weighted the model so players who played more games contributed more to the overall outcome of the model and significance of the treatment, we could better estimate the treatment effect. Player performance for players who only played a small number of games may not be as accurate as player performance for players with more games.

- Another factor to investigate is the impact of our treatment on long-term development. Even if not playing during the COVID season negatively impacted the development of any population of players, would this impact last forever? Or is it the case that these players would catch up to their counterparts who played during the COVID season in the long-term? As time passes and more data is collected post-COVID, future work could focus on assessing the long-term impact of playing/not playing during the COVID season or not playing during other seasons.

- We could also investigate the conditional average treatment effect (CATE) of playing during COVID more thoroughly. The time constraints and computational limits of our machines did not allow for a thorough analysis of CATE.

- With additional play level data we could attempt to estimate the effect of player interaction and control for it in our model so the independence condition for inference is met.

### Acknowledgments

Thank you to our external advisor Dr. Sam Ventura (and assistant Dominic Ventura) and our professor and advisor, Dr. Ron Yurko. We would also like to thank our TAs, Nick Kissel, Meg Ellingwood, Wanshan Li, Kenta Takatsu, and YJ Choe. Lastly, thank you to Professor Ben Baumer, Smith College and Dr. Ryne Vankrevelen, Elon University. We could not have completed this project without you all and we sincerely appreciate your help!


...
